{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca76e977",
   "metadata": {},
   "source": [
    "# Neural Network and Decision Tree Analysis\n",
    "\n",
    "I will be practicing supervised learning techniques gained from the machine learning course. While insurance.csv dataset is used throughout the process, it is to be noted that I do not intend to educe any meaningful outcome from the data. The data is solely used to implement the machine learning techniques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "685d9615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b3a69393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       age     sex     bmi  children smoker     region      charges\n",
       "0      19  female  27.900         0    yes  southwest  16884.92400\n",
       "1      18    male  33.770         1     no  southeast   1725.55230\n",
       "2      28    male  33.000         3     no  southeast   4449.46200\n",
       "3      33    male  22.705         0     no  northwest  21984.47061\n",
       "4      32    male  28.880         0     no  northwest   3866.85520\n",
       "...   ...     ...     ...       ...    ...        ...          ...\n",
       "1333   50    male  30.970         3     no  northwest  10600.54830\n",
       "1334   18  female  31.920         0     no  northeast   2205.98080\n",
       "1335   18  female  36.850         0     no  southeast   1629.83350\n",
       "1336   21  female  25.800         0     no  southwest   2007.94500\n",
       "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
       "\n",
       "[1338 rows x 7 columns]>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Datasets/insurance.csv\")\n",
    "df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9972e572",
   "metadata": {},
   "source": [
    "The dataset consists of 1338 examples with 7 columns. The columns are:\n",
    "\n",
    "| Features     | Data     |\n",
    "| ----------- | ----------- |\n",
    "| age    | 18-64   |\n",
    "| sex    | female/male    |\n",
    "| bmi    | 16.0-53.1   |\n",
    "| children    | 0-5    |\n",
    "| smoker    | yes/no    |\n",
    "| region    | SE/SW/NE/NW    |\n",
    "| charges    | 1120-63800    |\n",
    "\n",
    "# Neural Network Algorithm\n",
    "\n",
    "Neural network is the algorithm that try to mimic the brain. Its composed of the input layer, hidden layer(s), and the output layer. It's to be noted that the input layer has to be composed of only numerical data. We will go through the process to turn non-numeric data to numerical data, applying one hot encoding where necessary. One-hot encoding refers to splitting up categorical data into the number of categories, making each category a binary data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6dba75b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       age     bmi  children      charges  sex_male  smoker_yes  \\\n",
       "0      19  27.900         0  16884.92400         0           1   \n",
       "1      18  33.770         1   1725.55230         1           0   \n",
       "2      28  33.000         3   4449.46200         1           0   \n",
       "3      33  22.705         0  21984.47061         1           0   \n",
       "4      32  28.880         0   3866.85520         1           0   \n",
       "...   ...     ...       ...          ...       ...         ...   \n",
       "1333   50  30.970         3  10600.54830         1           0   \n",
       "1334   18  31.920         0   2205.98080         0           0   \n",
       "1335   18  36.850         0   1629.83350         0           0   \n",
       "1336   21  25.800         0   2007.94500         0           0   \n",
       "1337   61  29.070         0  29141.36030         0           1   \n",
       "\n",
       "      region_northeast  region_northwest  region_southeast  region_southwest  \n",
       "0                    0                 0                 0                 1  \n",
       "1                    0                 0                 1                 0  \n",
       "2                    0                 0                 1                 0  \n",
       "3                    0                 1                 0                 0  \n",
       "4                    0                 1                 0                 0  \n",
       "...                ...               ...               ...               ...  \n",
       "1333                 0                 1                 0                 0  \n",
       "1334                 1                 0                 0                 0  \n",
       "1335                 0                 0                 1                 0  \n",
       "1336                 0                 0                 0                 1  \n",
       "1337                 0                 1                 0                 0  \n",
       "\n",
       "[1338 rows x 10 columns]>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The following code convers 'male' to 1 'female' to 0\n",
    "df_encoded = pd.get_dummies(df, columns=['sex'], dtype=int, drop_first=True)\n",
    "\n",
    "#The following code convers 'yes' to 1 'no' to 0\n",
    "df_encoded = pd.get_dummies(df_encoded, columns=['smoker'], dtype=int, drop_first=True)\n",
    "\n",
    "#The following code implements one-hot encoding on 'region' feature\n",
    "df_encoded = pd.get_dummies(df_encoded, columns=['region',], dtype=int)\n",
    "df_encoded.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadcd835",
   "metadata": {},
   "source": [
    "I will implement the neural network algorithm to calculate the probability of a specific person being a smoker. Hence I need to drop the column and store in a different array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dca335c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1338,)\n"
     ]
    }
   ],
   "source": [
    "smoker = df_encoded['smoker_yes'].to_numpy()\n",
    "print(smoker.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c846a9",
   "metadata": {},
   "source": [
    "Before proceeding any further, I will start by scaling every feature by z-score normalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f156d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of            age       bmi  children   charges  sex_male  region_northeast  \\\n",
       "0    -1.438227 -0.453151 -0.908274  0.298472 -1.010141         -0.565056   \n",
       "1    -1.509401  0.509431 -0.078738 -0.953333  0.989221         -0.565056   \n",
       "2    -0.797655  0.383164  1.580335 -0.728402  0.989221         -0.565056   \n",
       "3    -0.441782 -1.305043 -0.908274  0.719574  0.989221         -0.565056   \n",
       "4    -0.512957 -0.292447 -0.908274 -0.776512  0.989221         -0.565056   \n",
       "...        ...       ...       ...       ...       ...               ...   \n",
       "1333  0.768185  0.050278  1.580335 -0.220468  0.989221         -0.565056   \n",
       "1334 -1.509401  0.206062 -0.908274 -0.913661 -1.010141          1.768415   \n",
       "1335 -1.509401  1.014499 -0.908274 -0.961237 -1.010141         -0.565056   \n",
       "1336 -1.295877 -0.797515 -0.908274 -0.930014 -1.010141         -0.565056   \n",
       "1337  1.551106 -0.261290 -0.908274  1.310563 -1.010141         -0.565056   \n",
       "\n",
       "      region_northwest  region_southeast  region_southwest  \n",
       "0            -0.566206         -0.611095          1.764821  \n",
       "1            -0.566206          1.635183         -0.566206  \n",
       "2            -0.566206          1.635183         -0.566206  \n",
       "3             1.764821         -0.611095         -0.566206  \n",
       "4             1.764821         -0.611095         -0.566206  \n",
       "...                ...               ...               ...  \n",
       "1333          1.764821         -0.611095         -0.566206  \n",
       "1334         -0.566206         -0.611095         -0.566206  \n",
       "1335         -0.566206          1.635183         -0.566206  \n",
       "1336         -0.566206         -0.611095          1.764821  \n",
       "1337          1.764821         -0.611095         -0.566206  \n",
       "\n",
       "[1338 rows x 9 columns]>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The code below implements z-score normalization on all the features of df_encoded\n",
    "df_encoded_drop = df_encoded.drop('smoker_yes', axis=1)\n",
    "df_z_scaled = df_encoded_drop.copy()\n",
    "\n",
    "for column in df_z_scaled.columns:\n",
    "    df_z_scaled[column] = (df_z_scaled[column]-df_z_scaled[column].mean()) / df_z_scaled[column].std()\n",
    "    \n",
    "df_z_scaled.head\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ec9e320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating nparray of all necessary features\n",
    "x_train = df_z_scaled[['age', 'bmi', 'children', 'charges', 'sex_male', 'region_northeast', 'region_northwest', \n",
    "                      'region_southeast', 'region_southwest']].to_numpy()\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bcebada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages necessary to implement neural network\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.losses import MeanSquaredError, BinaryCrossentropy\n",
    "from tensorflow.keras.activations import sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7edfb3-ce37-4450-bfb9-2e131c017c93",
   "metadata": {},
   "source": [
    "Each neuron has an activation. The activation can be linear, sigmoid or relu. Since the neural network aims to predict the chances of a person being a smoker, we will use sigmoid activation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b6c01d3-621e-4964-8479-1c9a44735766",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(9,)),\n",
    "        Dense(3, activation='sigmoid', name='layer1'),\n",
    "        Dense(1, activation='sigmoid', name='layer2')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c565e18-7f3e-45cb-922d-4ea7f3513f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (Dense)              (None, 3)                 30        \n",
      "                                                                 \n",
      " layer2 (Dense)              (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34\n",
      "Trainable params: 34\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d57e53c-a607-4a38-971a-8d3381ece85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1(9, 3):\n",
      " [[-0.0243066  -0.6859954   0.5371651 ]\n",
      " [-0.46246472 -0.33147198  0.54098004]\n",
      " [ 0.322226   -0.69254774 -0.66457164]\n",
      " [-0.06176066  0.36415774  0.04277718]\n",
      " [ 0.35824233 -0.3874821  -0.5155927 ]\n",
      " [-0.6085216   0.6997232   0.3565182 ]\n",
      " [-0.00584257  0.42300636  0.40524262]\n",
      " [-0.16720092  0.31298     0.66041654]\n",
      " [-0.5707931  -0.4807679  -0.70085335]] \n",
      "b1(3,): [0. 0. 0.]\n",
      "W2(3, 1):\n",
      " [[ 0.2804159]\n",
      " [-0.6430382]\n",
      " [ 0.7749101]] \n",
      "b2(1,): [0.]\n"
     ]
    }
   ],
   "source": [
    "#Describes the random biases and weights Tensorflow has initiated\n",
    "W1, b1 = model.get_layer(\"layer1\").get_weights()\n",
    "W2, b2 = model.get_layer(\"layer2\").get_weights()\n",
    "print(f\"W1{W1.shape}:\\n\", W1, f\"\\nb1{b1.shape}:\", b1)\n",
    "print(f\"W2{W2.shape}:\\n\", W2, f\"\\nb2{b2.shape}:\", b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "505c9fdf-ffea-4a90-9248-7864b5d19db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "42/42 [==============================] - 0s 292us/step - loss: 0.1252\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 0s 281us/step - loss: 0.1177\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 0s 235us/step - loss: 0.1111\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 0s 214us/step - loss: 0.1076\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 0s 226us/step - loss: 0.1062\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 0s 230us/step - loss: 0.1050\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 0s 226us/step - loss: 0.1030\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 0s 242us/step - loss: 0.1022\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 0s 215us/step - loss: 0.1010\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 0s 222us/step - loss: 0.1010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29b096850>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.01),\n",
    ")\n",
    "#epochs means the entire data set should be applied during training 10 times.\n",
    "model.fit(\n",
    "    x_train,smoker,            \n",
    "    epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98ced239-d595-4890-92c3-4530d1b5402d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1(9, 3):\n",
      " [[ 0.97016275  0.85319906 -0.9603485 ]\n",
      " [ 1.4447821   1.4506173  -1.4787594 ]\n",
      " [ 0.16927463  0.22694588 -0.1928326 ]\n",
      " [-3.2898934  -2.8743703   3.203796  ]\n",
      " [-0.0976601  -0.22181818  0.13050695]\n",
      " [-0.2908088   0.31043464  0.10585709]\n",
      " [-0.35587466  0.26202214  0.16500361]\n",
      " [-0.40883565  0.13569534  0.23385766]\n",
      " [-0.40078142  0.2355054   0.21645196]] \n",
      "b1(3,): [ 1.4255282  1.3723803 -1.46342  ]\n",
      "W2(3, 1):\n",
      " [[-3.2533317]\n",
      " [-4.443698 ]\n",
      " [ 2.9462836]] \n",
      "b2(1,): [-0.23018911]\n"
     ]
    }
   ],
   "source": [
    "#After fitting, the weights have been updated\n",
    "W1, b1 = model.get_layer(\"layer1\").get_weights()\n",
    "W2, b2 = model.get_layer(\"layer2\").get_weights()\n",
    "print(f\"W1{W1.shape}:\\n\", W1, f\"\\nb1{b1.shape}:\", b1)\n",
    "print(f\"W2{W2.shape}:\\n\", W2, f\"\\nb2{b2.shape}:\", b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62eaff9-8a76-43a8-881c-973dce68ab65",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "Since now we have a trained model, we can use it to make predictions. Since this model predicts a probability, in order to make decision there has to be a threshold. We will set 0.5 as the threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4cb78833-8602-4ca4-93ee-50fa8815f754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 9)\n",
      "(1, 9)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "predictions = \n",
      " [[4.8179663e-04]\n",
      " [7.3478907e-01]]\n"
     ]
    }
   ],
   "source": [
    "X_test = np.array([\n",
    "    [18, 33.770, 1, 1725.55230, 1, 0, 1, 0, 0],  # neg example\n",
    "    [19, 27.900, 0, 16884.92400, 0, 0, 0, 1, 0]])   # pos example\n",
    "print(X_test.shape)\n",
    "col_means = np.mean(df_encoded_drop, axis=0)\n",
    "col_means = col_means.values.reshape(1,-1)\n",
    "print(col_means.shape)\n",
    "col_std = np.std(df_encoded_drop, axis=0)\n",
    "col_std = col_std.values.reshape(1,-1)\n",
    "X_testn =(X_test - col_means) / col_std\n",
    "\n",
    "\n",
    "predictions = model.predict(X_testn)\n",
    "print(\"predictions = \\n\", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7a9ece-9a96-4f85-9e6e-dfa36225294c",
   "metadata": {},
   "source": [
    "To convert the probabilities to a decision, we apply a threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fe94addb-9fd7-4687-9cde-71f9983fa545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decisions = \n",
      "[[0]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "yhat = (predictions >= 0.5).astype(int)\n",
    "print(f\"decisions = \\n{yhat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c692789-5a35-46d1-a55f-6e5a308d0a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
